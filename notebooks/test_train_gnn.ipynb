{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25845012-8024-416a-ae9d-e43c05955ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/hgcal/hgcal_gravnet_model\n"
     ]
    }
   ],
   "source": [
    "%cd /home/naodell/work/hgcal/hgcal_gravnet_model\n",
    "\n",
    "import os, os.path as osp\n",
    "from time import strftime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import scripts.objectcondensation as object_condensation\n",
    "from torch_cmspepr.gravnet_model import GravnetModel\n",
    "from torch_cmspepr.dataset import TauDataset\n",
    "from scripts.lrscheduler import CyclicLRWithRestarts\n",
    "from scripts.nadam import Nadam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0ec380-e2b1-4b1a-8639-4337599f6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "# global options \n",
    "\n",
    "object_condensation.DEBUG = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')       \n",
    "print('Using device', device)                                               \n",
    "\n",
    "reduced_data = False\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d374439-ebb7-451b-bf51-b8e30cd03276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "data_path = 'local_data/npzs_all'\n",
    "dataset = TauDataset(data_path)\n",
    "dataset.blacklist([ # Remove a bunch of bad events                          \n",
    "    f'{data_path}/110_nanoML_98.npz',\n",
    "    f'{data_path}/113_nanoML_13.npz',\n",
    "    f'{data_path}/124_nanoML_77.npz',\n",
    "    f'{data_path}/128_nanoML_70.npz',\n",
    "    f'{data_path}/149_nanoML_90.npz',\n",
    "    f'{data_path}/153_nanoML_22.npz',\n",
    "    f'{data_path}/26_nanoML_93.npz',\n",
    "    f'{data_path}/32_nanoML_45.npz',                                           \n",
    "    f'{data_path}/5_nanoML_51.npz',                                            \n",
    "    f'{data_path}/86_nanoML_97.npz',\n",
    "    ])\n",
    "\n",
    "if reduced_data:\n",
    "    keep = .01\n",
    "    print(f'Keeping only {100.*keep:.1f}% of events for debugging')\n",
    "    dataset, _ = dataset.split(keep)\n",
    "    \n",
    "shuffle = True                                                              \n",
    "train_dataset, test_dataset = dataset.split(.8)                             \n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size = batch_size, \n",
    "                          shuffle = shuffle\n",
    "                         )\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size = batch_size, \n",
    "                         shuffle = shuffle\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8658c8c7-1db4-40a8-b557-52eb98378292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and configure it\n",
    "\n",
    "model = GravnetModel(input_dim=9, output_dim=4).to(device)\n",
    "                                                                            \n",
    "epoch_size = len(train_loader.dataset)                                      \n",
    "#optimizer = Nadam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
    "# scheduler = CyclicLRWithRestarts(optimizer, batch_size, epoch_size, restart_period=400, t_mult=1.1, policy=\"cosine\")\n",
    "                                                                            \n",
    "loss_offset = 1. # To prevent a negative loss from ever occuring            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe89430a-eada-461d-8848-0aa441b808d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss\n",
    "\n",
    "def loss_fn(out, data, s_c=1., return_components=False):                    \n",
    "    device = out.device                                                     \n",
    "    pred_betas = torch.sigmoid(out[:,0])                                    \n",
    "    pred_cluster_space_coords = out[:,1:4]                                  \n",
    "    # pred_cluster_properties = out[:,3:]                                   \n",
    "    assert all(t.device == device for t in [pred_betas, pred_cluster_space_coords, data.y, data.batch,                                                         \n",
    "        # pred_cluster_properties, data.truth_cluster_props                 \n",
    "        ])                                                                  \n",
    "    \n",
    "    out_oc = object_condensation.calc_LV_Lbeta(                              \n",
    "        pred_betas,                                                         \n",
    "        pred_cluster_space_coords,                                          \n",
    "        data.y.long(),                                                      \n",
    "        data.batch,                                                         \n",
    "        return_components = return_components                                 \n",
    "        )                                                                   \n",
    "    \n",
    "    if return_components:                                                   \n",
    "        return out_oc                                                       \n",
    "    else:                                                                   \n",
    "        LV, Lbeta = out_oc                                                  \n",
    "        return LV + Lbeta + loss_offset                                     \n",
    "    \n",
    "    # Lp = objectcondensation.calc_Lp(                                                                                                                                                                                                                  \n",
    "    #     pred_betas,                                                       \n",
    "    #     data.y.long(),                                                    \n",
    "    #     pred_cluster_properties,                                          \n",
    "    #     data.truth_cluster_props                                          \n",
    "    #     )                                                                 \n",
    "    # return Lp + s_c*(LV + Lbeta)                                          \n",
    "                                                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4de41db-f538-4b5b-864f-3459069662ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test methods\n",
    "\n",
    "def train(epoch, train_loader, tb_writer):\n",
    "    #print('Training epoch', epoch)\n",
    "    model.train()\n",
    "    # scheduler.step()\n",
    "    try:\n",
    "        pbar = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "        pbar.set_postfix({'loss': '?'})\n",
    "        for i, data in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            result = model(data.x, data.batch)\n",
    "            loss = loss_fn(result, data)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.batch_step()\n",
    "            pbar.set_postfix({'loss': float(loss)})\n",
    "        \n",
    "            tb_writer.add_scalar('training loss', loss, i)\n",
    "        return loss\n",
    "            \n",
    "    except Exception:\n",
    "        print('Exception encountered:', data, ', npzs:')\n",
    "        print('  ' + '\\n  '.join([train_dataset.npzs[int(i)] for i in data.inpz]))\n",
    "        raise\n",
    "\n",
    "def test(epoch):\n",
    "    N_test = len(test_loader)\n",
    "    loss_components = {}\n",
    "    \n",
    "    def update(components):\n",
    "        for key, value in components.items():\n",
    "            if not key in loss_components: loss_components[key] = 0.\n",
    "            loss_components[key] += value\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in tqdm(test_loader, total=len(test_loader), leave=False):\n",
    "            data = data.to(device)\n",
    "            result = model(data.x, data.batch)\n",
    "            update(loss_fn(result, data, return_components=True))\n",
    "            \n",
    "    # Divide by number of entries\n",
    "    for key in loss_components:\n",
    "        loss_components[key] /= N_test\n",
    "        \n",
    "    # Compute total loss and do printout\n",
    "    test_loss = loss_offset + loss_components['L_V']+loss_components['L_beta']\n",
    "    \n",
    "    #print('test ' + object_condensation.formatted_loss_components_string(loss_components))\n",
    "    #print(f'Returning {test_loss}')\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0d6939-05ea-4a47-89b6-eae861b9c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional useful utility functions\n",
    "\n",
    "def write_checkpoint(checkpoint_number=None, best=False):\n",
    "    ckpt_dir = strftime('checkpoints/gravnet_%b%d_%H%M') #if args.ckptdir is None else args.ckptdir\n",
    "    ckpt = 'ckpt_best.pth.tar' if best else 'ckpt_{0}.pth.tar'.format(checkpoint_number)\n",
    "    ckpt = osp.join(ckpt_dir, ckpt)\n",
    "    if best: \n",
    "        print('Saving epoch {0} as new best'.format(checkpoint_number))\n",
    "    \n",
    "    if not reduced_data:\n",
    "        os.makedirs(ckpt_dir, exist_ok=True)\n",
    "        torch.save(dict(model=model.state_dict()), ckpt)\n",
    "\n",
    "def debug():\n",
    "    oc.DEBUG = True\n",
    "    dataset = TauDataset('data/taus')\n",
    "    dataset.npzs = [\n",
    "        # 'data/taus/49_nanoML_84.npz',\n",
    "        # 'data/taus/37_nanoML_4.npz',\n",
    "        'data/taus/26_nanoML_93.npz',\n",
    "        # 'data/taus/142_nanoML_75.npz',\n",
    "        ]\n",
    "    for data in DataLoader(dataset, batch_size=len(dataset), shuffle=False): break\n",
    "    \n",
    "    print(data.y.sum())\n",
    "    model = GravnetModel(input_dim=9, output_dim=4)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x, data.batch)\n",
    "        \n",
    "    pred_betas = torch.sigmoid(out[:,0])\n",
    "    pred_cluster_space_coords = out[:,1:4]\n",
    "    out_oc = oc.calc_LV_Lbeta(\n",
    "        pred_betas,\n",
    "        pred_cluster_space_coords,\n",
    "        data.y.long(),\n",
    "        data.batch.long()\n",
    "        )\n",
    "\n",
    "def run_profile():\n",
    "    from torch.profiler import profile, record_function, ProfilerActivity\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device', device)\n",
    "\n",
    "    batch_size = 2\n",
    "    n_batches = 2\n",
    "    shuffle = True\n",
    "    dataset = TauDataset('data/taus')\n",
    "    dataset.npzs = dataset.npzs[:batch_size*n_batches]\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    print(f'Running profiling for {len(dataset)} events, batch_size={batch_size}, {len(loader)} batches')\n",
    "\n",
    "    model = GravnetModel(input_dim=9, output_dim=8).to(device)\n",
    "    epoch_size = len(loader.dataset)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "\n",
    "    print('Start limited training loop')\n",
    "    model.train()\n",
    "    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            pbar = tqdm(loader, total=len(loader), leave=False)\n",
    "            pbar.set_postfix({'loss': '?'})\n",
    "            for i, data in enumerate(pbar):\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                result = model(data.x, data.batch)\n",
    "                loss = loss_fn(result, data)\n",
    "                print(f'loss={float(loss)}')\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.set_postfix({'loss': float(loss)})\n",
    "                \n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time\", row_limit=10))\n",
    "    # Other valid keys:\n",
    "    # cpu_time, cuda_time, cpu_time_total, cuda_time_total, cpu_memory_usage,\n",
    "    # cuda_memory_usage, self_cpu_memory_usage, self_cuda_memory_usage, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6ef1fe-b997-400f-a1f0-b7e1cab289b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2986f98f404056a383e252dc30dec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa49601dad984566b356ea90b48ab92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception encountered: Batch(batch=[614948], inpz=[32], ptr=[33], truth_cluster_props=[614948, 5], x=[614948, 9], y=[614948]) , npzs:\n",
      "  local_data/npzs_all/4_nanoML_35.npz\n",
      "  local_data/npzs_all/102_nanoML_13.npz\n",
      "  local_data/npzs_all/18_nanoML_35.npz\n",
      "  local_data/npzs_all/137_nanoML_96.npz\n",
      "  local_data/npzs_all/137_nanoML_72.npz\n",
      "  local_data/npzs_all/150_nanoML_73.npz\n",
      "  local_data/npzs_all/200_nanoML_62.npz\n",
      "  local_data/npzs_all/120_nanoML_38.npz\n",
      "  local_data/npzs_all/170_nanoML_75.npz\n",
      "  local_data/npzs_all/178_nanoML_1.npz\n",
      "  local_data/npzs_all/112_nanoML_55.npz\n",
      "  local_data/npzs_all/120_nanoML_73.npz\n",
      "  local_data/npzs_all/52_nanoML_98.npz\n",
      "  local_data/npzs_all/16_nanoML_59.npz\n",
      "  local_data/npzs_all/134_nanoML_28.npz\n",
      "  local_data/npzs_all/121_nanoML_99.npz\n",
      "  local_data/npzs_all/38_nanoML_39.npz\n",
      "  local_data/npzs_all/26_nanoML_89.npz\n",
      "  local_data/npzs_all/117_nanoML_69.npz\n",
      "  local_data/npzs_all/19_nanoML_98.npz\n",
      "  local_data/npzs_all/50_nanoML_32.npz\n",
      "  local_data/npzs_all/42_nanoML_76.npz\n",
      "  local_data/npzs_all/165_nanoML_15.npz\n",
      "  local_data/npzs_all/15_nanoML_44.npz\n",
      "  local_data/npzs_all/165_nanoML_55.npz\n",
      "  local_data/npzs_all/176_nanoML_24.npz\n",
      "  local_data/npzs_all/169_nanoML_87.npz\n",
      "  local_data/npzs_all/44_nanoML_57.npz\n",
      "  local_data/npzs_all/145_nanoML_44.npz\n",
      "  local_data/npzs_all/135_nanoML_88.npz\n",
      "  local_data/npzs_all/133_nanoML_61.npz\n",
      "  local_data/npzs_all/131_nanoML_21.npz\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.02 GiB (GPU 0; 10.91 GiB total capacity; 6.92 GiB already allocated; 1.95 GiB free; 7.57 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15514/2328736959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtb_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mwrite_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15514/2114170255.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, train_loader, tb_writer)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hgcal-ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/hgcal/pytorch_cmspepr/torch_cmspepr/gravnet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mx_gravnet_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# To store intermediate outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgravnet_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravnet_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgravnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mx_gravnet_per_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gravnet_per_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hgcal-ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/hgcal/pytorch_cmspepr/torch_cmspepr/gravnet_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravnet_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_gravnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hgcal-ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/hgcal/pytorch_cmspepr/torch_cmspepr/gravnet_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         out = self.propagate(edge_index, x=(h_l, None),\n\u001b[0m\u001b[1;32m     88\u001b[0m                              \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                              size=(s_l.size(0), s_l.size(0)))\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hgcal-ml/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Otherwise, run both functions in separation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             coll_dict = self.__collect__(self.__user_args__, edge_index, size,\n\u001b[0m\u001b[1;32m    234\u001b[0m                                          kwargs)\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hgcal-ml/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__collect__\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_size__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     data = self.__lift__(data, edge_index,\n\u001b[0m\u001b[1;32m    158\u001b[0m                                          j if arg[-2:] == '_j' else i)\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/hgcal-ml/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__lift__\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.02 GiB (GPU 0; 10.91 GiB total capacity; 6.92 GiB already allocated; 1.95 GiB free; 7.57 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "min_loss = 1e9\n",
    "n_epochs = 50\n",
    "tb_writer = SummaryWriter(log_dir='logs')\n",
    "for i_epoch in tqdm(range(n_epochs)):\n",
    "    train_loss = train(i_epoch, train_loader, tb_writer)\n",
    "    write_checkpoint(i_epoch)\n",
    "    test_loss = test(i_epoch)\n",
    "    if test_loss < min_loss:\n",
    "        min_loss = test_loss\n",
    "        write_checkpoint(i_epoch, best=True)\n",
    "    \n",
    "    tb_writer.add_scalar('test loss', test_loss, i_epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdbb8d-39ec-4a5b-b598-10bd9cee07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db8173-9394-4788-b211-d7d701dc42f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
